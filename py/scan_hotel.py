import os
import re
import random
import requests
import concurrent.futures
from urllib.parse import urlparse
from tqdm import tqdm  # å¼•å…¥è¿›åº¦æ¡åº“

# ===============================
# é…ç½®åŒº
# ===============================
HOTEL_DIR = "./hotel"
TIMEOUT = 3
MAX_WORKERS = 100
HEADERS = {"User-Agent": "Lavf/58.29.100"}

def get_smart_tasks():
    """è§£æå¹¶åˆå¹¶ç½‘æ®µ"""
    tasks = {}
    if not os.path.exists(HOTEL_DIR):
        return {}

    print("Step 1: ğŸ” æ­£åœ¨åˆ†æç°æœ‰åº“æ–‡ä»¶...")
    for file in os.listdir(HOTEL_DIR):
        if not file.endswith(".m3u"): continue
        with open(os.path.join(HOTEL_DIR, file), "r", encoding="utf-8", errors="ignore") as f:
            urls = re.findall(r'http://[^\s,]+', f.read())
            for url in urls:
                parsed = urlparse(url)
                host_parts = parsed.netloc.split(':')
                ip = host_parts[0]
                port = host_parts[1] if len(host_parts) > 1 else "80"
                ip_parts = ip.split('.')
                if len(ip_parts) == 4:
                    prefix = ".".join(ip_parts[:3]) 
                    key = f"{prefix}:{port}"
                    if key not in tasks:
                        tasks[key] = parsed.path + "?" + parsed.query
    return tasks

def check_ip(url):
    """æ¢æµ‹å•ä¸ª IPï¼Œè¿”å›ç»“æœä¾›è¿›åº¦æ¡å®æ—¶æ˜¾ç¤º"""
    try:
        r = requests.get(url, headers=HEADERS, timeout=TIMEOUT, stream=True)
        if r.status_code == 200:
            return url
    except:
        pass
    return None

def run():
    tasks = get_smart_tasks()
    if not tasks:
        print("âŒ æœªå‘ç°å¯æ‰«æçš„ç‰¹å¾ã€‚")
        return

    print(f"ğŸ§¬ è¯†åˆ«åˆ° {len(tasks)} ä¸ªå”¯ä¸€ C æ®µã€‚å³å°†å¼€å§‹æ‰«æ...")
    
    all_discovered = []
    
    # é€ä¸ªç½‘æ®µæ‰«æï¼Œå±•ç¤ºè¯¦ç»†è¿‡ç¨‹
    for key, suffix in tasks.items():
        prefix, port = key.split(':')
        scan_list = [f"http://{prefix}.{i}:{port}{suffix}" for i in range(1, 255)]
        
        # ä½¿ç”¨ tqdm å±•ç¤ºå½“å‰ç½‘æ®µçš„æ‰«æè¿›åº¦
        # desc è®¾ç½®å·¦ä¾§æè¿°ï¼Œleave=False æ‰«æå®Œä¸€ä¸ªæ®µåæ¸…é™¤è¯¥è¿›åº¦æ¡ï¼Œä¿æŒç•Œé¢æ•´æ´
        pbar = tqdm(total=len(scan_list), desc=f"ğŸ“¡ æ‰«æä¸­ {prefix}.x", unit="ip", leave=True)
        
        valid_in_segment = []
        with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
            futures = [executor.submit(check_ip, url) for url in scan_list]
            
            for future in concurrent.futures.as_completed(futures):
                res = future.result()
                if res:
                    valid_in_segment.append(res)
                    # å½“å‘ç°æœ‰æ•ˆ IP æ—¶ï¼Œåœ¨è¿›åº¦æ¡ä¸Šæ–¹æ‰“å°ä¸€æ¡æˆåŠŸè®°å½•
                    pbar.write(f"  âœ¨ [å‘ç°å­˜æ´»] {res}")
                pbar.update(1) # æ¯å®Œæˆä¸€ä¸ªä»»åŠ¡ï¼Œè¿›åº¦æ¡å‰è¿› 1
        
        pbar.close() # ç»“æŸå½“å‰æ®µè¿›åº¦æ¡
        if valid_in_segment:
            all_discovered.extend(valid_in_segment)
            print(f"âœ… ç½‘æ®µ {prefix}.x æ‰«æå®Œæˆï¼Œæ–°å¢ {len(valid_in_segment)} ä¸ªèŠ‚ç‚¹")

    # ä¿å­˜æœ€ç»ˆç»“æœ
    if all_discovered:
        hosts = sorted(list(set([urlparse(u).netloc for u in all_discovered])))
        with open("active_hotel_hosts.txt", "w", encoding="utf-8") as f:
            f.write("\n".join(hosts))
        print(f"\nğŸ‰ æ‰«æç»“æŸï¼å…±å‘ç° {len(hosts)} ä¸ªå­˜æ´»é…’åº—ä¸»æœºã€‚")

if __name__ == "__main__":
    run()
