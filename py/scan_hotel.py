import os, re, json, requests, concurrent.futures
from urllib.parse import urlparse
from tqdm import tqdm

HOTEL_DIR = "./hotel"
MAP_FILE = "py/scan_map.json"
TIMEOUT = 3
MAX_WORKERS = 100
HEADERS = {"User-Agent": "Lavf/58.29.100"}

def run_scan():
    print("\n" + "="*50)
    print("ğŸš€ é…’åº—æºåŸºå› æ‰«æä»»åŠ¡å¼€å§‹")
    print("="*50)

    tasks = {} 
    if not os.path.exists(HOTEL_DIR):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°ç›®å½• {HOTEL_DIR}")
        return
    
    # æå–åŸºå› 
    for file in os.listdir(HOTEL_DIR):
        if file.endswith(".m3u") and not file.startswith("REBORN"):
            with open(os.path.join(HOTEL_DIR, file), "r", encoding="utf-8", errors="ignore") as f:
                urls = re.findall(r'http://([\d\.]+:\d+)(/[^\s,]+)', f.read())
                for host, path in urls:
                    prefix = ".".join(host.split('.')[:3])
                    port = host.split(':')[-1]
                    key = f"{prefix}:{port}"
                    if key not in tasks:
                        tasks[key] = {"old_host": host, "path": path}

    print(f"ğŸ“Š å·²æå–ç‰¹å¾ç½‘æ®µ: {len(tasks)} ä¸ª")
    
    scan_results = []
    
    for key, info in tasks.items():
        prefix, port = key.split(':')
        scan_list = [f"http://{prefix}.{i}:{port}{info['path']}" for i in range(1, 255)]
        
        valid_found = []
        # desc è®©è¿›åº¦æ¡æ˜¾ç¤ºå½“å‰æ­£åœ¨æ‰«å“ªä¸ªæ®µ
        pbar = tqdm(total=len(scan_list), desc=f"ğŸ“¡ æ¢æµ‹ {prefix}.x", bar_format='{l_bar}{bar:20}{r_bar}')
        
        def check_url(url):
            try:
                r = requests.get(url, headers=HEADERS, timeout=TIMEOUT, stream=True)
                return url if r.status_code == 200 else None
            except: return None

        with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
            futures = [executor.submit(check_url, u) for u in scan_list]
            for future in concurrent.futures.as_completed(futures):
                res = future.result()
                if res:
                    new_host = urlparse(res).netloc
                    valid_found.append(new_host)
                    # pbar.write å¯ä»¥ä¿è¯æ‰“å°ä¿¡æ¯ä¸ç ´åè¿›åº¦æ¡ç»“æ„
                    pbar.write(f"  âœ¨ [å‰å°å‘ç°å­˜æ´»] -> {new_host}")
                pbar.update(1)
        pbar.close()
        
        for v_host in valid_found:
            scan_results.append({"old_host": info['old_host'], "new_host": v_host})

    os.makedirs("py", exist_ok=True)
    with open(MAP_FILE, "w", encoding="utf-8") as f:
        json.dump(scan_results, f, indent=4, ensure_ascii=False)
    
    print("\n" + "="*50)
    print(f"âœ… æ‰«æé˜¶æ®µç»“æŸï¼Œå…±æ•è· {len(scan_results)} ä¸ªæ´»è·ƒ IP")
    print("="*50 + "\n")

if __name__ == "__main__":
    run_scan()
